import os
import time
import re
import json
from openai import OpenAI
from prompts import PROMPT_BATCH_ANALYSIS, PROMPT_FINAL_MERGE, PROMPT_MIMIC_TRANSLATE
from dotenv import load_dotenv

# --- 0. –ë–ï–ó–û–ü–ê–°–ù–ê–Ø –ó–ê–ì–†–£–ó–ö–ê –ö–õ–Æ–ß–ê ---
# override=True –∑–∞—Å—Ç–∞–≤–ª—è–µ—Ç Python –ø–µ—Ä–µ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª, –¥–∞–∂–µ –µ—Å–ª–∏ —Å—Ç–∞—Ä—ã–π –∫–ª—é—á –∑–∞—Å—Ç—Ä—è–ª –≤ –ø–∞–º—è—Ç–∏
load_dotenv(override=True) 

api_key = os.getenv("OPENAI_API_KEY")

# --- –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê (–ß–¢–û–ë–´ –¢–´ –í–ò–î–ï–õ, –ö–ê–ö–û–ô –ö–õ–Æ–ß –ó–ê–ì–†–£–ó–ò–õ–°–Ø) ---
if api_key:
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ —Ö–≤–æ—Å—Ç–∏–∫ –∫–ª—é—á–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
    print(f"üîë DEBUG: –ö–ª—é—á —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω. –ö–æ–Ω—Ü–æ–≤–∫–∞: ...{api_key[-4:]}")
else:
    print("‚ùå DEBUG: –§–∞–π–ª .env –ø—Ä–æ—á–∏—Ç–∞–Ω, –Ω–æ –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è OPENAI_API_KEY –ø—É—Å—Ç–∞—è.")

if not api_key:
    print("\n‚ùå –û–®–ò–ë–ö–ê: –ù–µ –Ω–∞–π–¥–µ–Ω API –∫–ª—é—á!")
    print("1. –ü—Ä–æ–≤–µ—Ä—å, —á—Ç–æ —Ñ–∞–π–ª –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è —Ä–æ–≤–Ω–æ '.env' (–∞ –Ω–µ .env.txt)")
    print("2. –í–Ω—É—Ç—Ä–∏ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å: OPENAI_API_KEY=sk-proj-—Ç–≤–æ–π_–∫–ª—é—á")
    exit()

client = OpenAI(api_key=api_key)

# --- –ù–ê–°–¢–†–û–ô–ö–ò ---
DIRS = {
    "examples": "examples",       # –ü–∞–ø–∫–∞ —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏ (source + target)
    "style": "style_guide",       # –ü–∞–ø–∫–∞ –¥–ª—è DNA
    "input": "to_translate",      # –ü–∞–ø–∫–∞ —Å –∫–Ω–∏–≥–æ–π –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞
    "output": "output"            # –ü–∞–ø–∫–∞ –¥–ª—è –≥–æ—Ç–æ–≤–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞
}

# –†–∞–∑–º–µ—Ä –∫—É—Å–∫–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (gpt-4o-mini –µ—Å—Ç –º–Ω–æ–≥–æ –∏ –±—ã—Å—Ç—Ä–æ)
ANALYSIS_CHUNK_SIZE = 40000 
# –†–∞–∑–º–µ—Ä –∫—É—Å–∫–∞ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ (gpt-4o –ª—É—á—à–µ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –Ω–µ–±–æ–ª—å—à–∏–º–∏ –∫—É—Å–∫–∞–º–∏)
TRANSLATION_CHUNK_SIZE = 6000 

# --- –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò ---

def read_txt(path):
    try:
        with open(path, 'r', encoding='utf-8') as f: return f.read()
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {path}: {e}")
        return ""

def save_txt(path, content):
    with open(path, 'w', encoding='utf-8') as f: f.write(content)

def clean_json(text):
    """–ß–∏—Å—Ç–∏—Ç –æ—Ç–≤–µ—Ç –æ—Ç –º–∞—Ä–∫–¥–∞—É–Ω–∞ ```json ... ```"""
    match = re.search(r"```json\s*(.*?)\s*```", text, re.DOTALL)
    if match: return match.group(1)
    return text.replace("```json", "").replace("```", "")

def call_llm(prompt, model="gpt-4o"):
    """
    –£–º–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –≤—ã–∑–æ–≤–∞ API.
    –ï—Å–ª–∏ –ª–æ–≤–∏—Ç –æ—à–∏–±–∫—É –ª–∏–º–∏—Ç–æ–≤ (Rate Limit) ‚Äî –∂–¥–µ—Ç –∏ –ø—Ä–æ–±—É–µ—Ç —Å–Ω–æ–≤–∞.
    """
    for attempt in range(3):
        try:
            resp = client.chat.completions.create(
                model=model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.4
            )
            return resp.choices[0].message.content
        except Exception as e:
            err_msg = str(e).lower()
            print(f"‚ö†Ô∏è API Error ({model}, –ø–æ–ø—ã—Ç–∫–∞ {attempt+1}): {e}")
            
            # –ï—Å–ª–∏ –ø—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç —Ç–æ–∫–µ–Ω–æ–≤ ‚Äî –∂–¥–µ–º –¥–æ–ª—å—à–µ
            if "rate_limit" in err_msg or "429" in err_msg:
                print("‚è≥ –õ–∏–º–∏—Ç API –ø—Ä–µ–≤—ã—à–µ–Ω. –ñ–¥—É 20 —Å–µ–∫—É–Ω–¥...")
                time.sleep(20)
            else:
                time.sleep(5)
    return ""

def split_text_smart(text, limit):
    """–†–µ–∂–µ—Ç —Ç–µ–∫—Å—Ç –ø–æ –∞–±–∑–∞—Ü–∞–º, –Ω–µ —Ä–∞–∑—Ä—ã–≤–∞—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è."""
    paragraphs = text.split('\n')
    chunks = []
    current_chunk = []
    current_len = 0
    for p in paragraphs:
        # +1 —É—á–∏—Ç—ã–≤–∞–µ—Ç —Å–∏–º–≤–æ–ª –ø–µ—Ä–µ–Ω–æ—Å–∞ —Å—Ç—Ä–æ–∫–∏
        if current_len + len(p) > limit and current_chunk:
            chunks.append("\n".join(current_chunk))
            current_chunk = []
            current_len = 0
        current_chunk.append(p)
        current_len += len(p) + 1
    if current_chunk: chunks.append("\n".join(current_chunk))
    return chunks

# --- –ì–õ–£–ë–û–ö–ò–ô –ê–ù–ê–õ–ò–ó (DEEP SCAN) ---

def perform_deep_scan():
    print("\nüïµÔ∏è –ù–ê–ß–ò–ù–ê–Æ –ì–õ–£–ë–û–ö–û–ï –°–ö–ê–ù–ò–†–û–í–ê–ù–ò–ï –í–°–ï–• –ö–ù–ò–ì...")
    
    files = sorted(os.listdir(DIRS["examples"]))
    sources = [f for f in files if "_source.txt" in f]
    
    all_notes = [] 
    full_reference_text = ""

    if not sources:
        print("‚ùå –ù–µ—Ç —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ examples.")
        return None, None

    # 1. –°–ö–ê–ù–ò–†–û–í–ê–ù–ò–ï (MAP) - –ß–∏—Ç–∞–µ–º –≤—Å–µ –∫–Ω–∏–≥–∏
    total_files = len(sources)
    for idx, src in enumerate(sources):
        tgt = src.replace("_source.txt", "_target.txt")
        if tgt not in files: continue
        
        print(f"   üìñ –ß–∏—Ç–∞—é –∫–Ω–∏–≥—É {idx+1}/{total_files}: {src}...")
        
        s_text = read_txt(os.path.join(DIRS["examples"], src))
        t_text = read_txt(os.path.join(DIRS["examples"], tgt))
        
        # –°–æ—Ö—Ä–∞–Ω–∏–º –∫—É—Å–æ—á–µ–∫ –¥–ª—è reference (–ø—Ä–∏–º–µ—Ä —Ç–æ–Ω–∞)
        if len(full_reference_text) < 5000:
            full_reference_text += t_text[:5000]

        s_chunks = split_text_smart(s_text, ANALYSIS_CHUNK_SIZE)
        t_chunks = split_text_smart(t_text, ANALYSIS_CHUNK_SIZE)
        
        limit = min(len(s_chunks), len(t_chunks))
        
        for i in range(limit):
            print(f"      üî¨ –ê–Ω–∞–ª–∏–∑ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞ {i+1}/{limit}...")
            combined_chunk = f"ORIGINAL:\n{s_chunks[i]}\n\nTRANSLATION:\n{t_chunks[i]}"
            
            # –í–ê–ñ–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ–º gpt-4o-mini –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞. 
            notes = call_llm(PROMPT_BATCH_ANALYSIS.format(content_chunk=combined_chunk), model="gpt-4o-mini")
            if notes:
                all_notes.append(notes)

    # 2. –°–ë–û–†–ö–ê (REDUCE) - –°–æ–∑–¥–∞–µ–º DNA
    print("\nüß† –û–ë–™–ï–î–ò–ù–Ø–Æ –î–ê–ù–ù–´–ï –í –ï–î–ò–ù–´–ô DNA...")
    
    raw_data = "\n\n=== –ó–ê–ú–ï–¢–ö–ò ===\n".join(all_notes)
    
    # –£–º–Ω–∞—è –ª–æ–≥–∏–∫–∞: –ø—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã, —á—Ç–æ–±—ã –≤–ª–µ–∑—Ç—å –≤ –ª–∏–º–∏—Ç
    try_limits = [160000, 80000, 40000] 
    
    final_json = None
    
    for limit in try_limits:
        print(f"   üîÑ –ü—Ä–æ–±—É—é —Å–æ–±—Ä–∞—Ç—å DNA (–æ–±—ä–µ–º –¥–∞–Ω–Ω—ã—Ö: {limit} —Å–∏–º–≤)...")
        safe_data = raw_data[:limit]
        
        # –°–Ω–æ–≤–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º gpt-4o-mini –¥–ª—è —Å–±–æ—Ä–∫–∏ –±–æ–ª—å—à–æ–≥–æ –æ–±—ä–µ–º–∞
        final_json_str = call_llm(PROMPT_FINAL_MERGE.format(raw_notes=safe_data), model="gpt-4o-mini")
        cleaned = clean_json(final_json_str)
        
        if cleaned and len(cleaned) > 20 and "Error" not in cleaned:
            final_json = cleaned
            break # –£—Å–ø–µ—Ö!
        else:
            print("   ‚ö†Ô∏è –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –¥–∞–Ω–Ω—ã—Ö. –£—Ä–µ–∑–∞—é –∏ –ø—Ä–æ–±—É—é —Å–Ω–æ–≤–∞...")

    if not final_json:
        print("‚ùå –û–®–ò–ë–ö–ê: –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å DNA. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–∞–π–ª—ã –ø—Ä–∏–º–µ—Ä–æ–≤.")
        return None, None

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    dna_path = os.path.join(DIRS["style"], "translator_dna.json")
    save_txt(dna_path, final_json)
    print("‚úÖ MASTER DNA –£–°–ü–ï–®–ù–û –°–û–ó–î–ê–ù.")
    
    return final_json, full_reference_text

# --- MAIN ---

def main():
    # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫–∏ –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
    for d in DIRS.values(): os.makedirs(d, exist_ok=True)
    
    dna_path = os.path.join(DIRS["style"], "translator_dna.json")
    
    # –õ–æ–≥–∏–∫–∞ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞
    if os.path.exists(dna_path):
        print("‚ÑπÔ∏è –ù–∞–π–¥–µ–Ω —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π DNA.")
        choice = input("–ü–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å –µ–≥–æ –∑–∞–Ω–æ–≤–æ (—Å–∫–∞–Ω–∏—Ä–æ–≤–∞—Ç—å –≤—Å–µ –∫–Ω–∏–≥–∏)? (y/n): ")
        if choice.lower() == 'y':
            style_dna, ref_text = perform_deep_scan()
        else:
            style_dna = read_txt(dna_path)
            ref_text = "–¢–µ–∫—Å—Ç –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞ —Å—Ç–∏–ª—è..." 
    else:
        style_dna, ref_text = perform_deep_scan()

    if not style_dna: return

    # --- –ü–ï–†–ï–í–û–î ---
    input_files = [f for f in os.listdir(DIRS["input"]) if f.endswith(".txt")]
    
    if not input_files:
        print(f"üìÇ –ü–∞–ø–∫–∞ {DIRS['input']} –ø—É—Å—Ç–∞. –ü–æ–ª–æ–∂–∏—Ç–µ —Ç—É–¥–∞ .txt —Ñ–∞–π–ª.")
        return

    for filename in input_files:
        print(f"\nüöÄ –ü–ï–†–ï–í–û–î –ö–ù–ò–ì–ò: {filename}")
        full_source = read_txt(os.path.join(DIRS["input"], filename))
        chunks = split_text_smart(full_source, TRANSLATION_CHUNK_SIZE)
        
        full_translation = []
        for i, chunk in enumerate(chunks):
            print(f"   ‚è≥ –ü–µ—Ä–µ–≤–æ–∂—É —á–∞—Å—Ç—å {i+1}/{len(chunks)}...")
            
            prompt = PROMPT_MIMIC_TRANSLATE.format(
                style_json=style_dna,
                reference_sample=ref_text[:2000],
                source_text=chunk
            )
            
            # –í–ê–ñ–ù–û: –î–ª—è —Å–∞–º–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º gpt-4o (–º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ)
            res = call_llm(prompt, model="gpt-4o") 
            res = clean_json(res)
            
            full_translation.append(res)
            
            # –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
            save_txt(os.path.join(DIRS["output"], f"temp_{filename}"), "\n".join(full_translation))

        # –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
        final_path = os.path.join(DIRS["output"], filename.replace(".txt", "_RU.txt"))
        save_txt(final_path, "\n".join(full_translation))
        print(f"üèÅ –ì–û–¢–û–í–û! –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {final_path}")

        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        if os.path.exists(os.path.join(DIRS["output"], f"temp_{filename}")):
            os.remove(os.path.join(DIRS["output"], f"temp_{filename}"))

if __name__ == "__main__":
    main()
